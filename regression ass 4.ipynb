{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40141660-b0e8-43f5-968c-7297e21754b0",
   "metadata": {},
   "source": [
    "# Q1. What is Lasso Regression, and how does it differ from other regression techniques?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d65309a-4a75-47a0-89c4-a7e54bfceda3",
   "metadata": {},
   "source": [
    "Lasso Regression, short for \"Least Absolute Shrinkage and Selection Operator,\" is a linear regression technique that adds a penalty term to the standard linear regression objective function. This penalty term encourages the model to have smaller and more sparse coefficients by adding the sum of the absolute values of the coefficients (L1 regularization) to the loss function. Key differences from other regression techniques include its ability to perform feature selection by setting some coefficients to exactly zero, which other linear models like Ridge Regression do not do."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94892da4-2557-4ea7-9bf5-74594ee6abb8",
   "metadata": {},
   "source": [
    "# Q2. What is the main advantage of using Lasso Regression in feature selection?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3daab4-6412-4cc8-b680-29d8d03c34f4",
   "metadata": {},
   "source": [
    "The main advantage of Lasso Regression in feature selection is its ability to automatically identify and exclude less relevant features from the model by setting their coefficients to zero. This feature selection capability can lead to simpler and more interpretable models, reduce overfitting, and improve model generalization by focusing on the most important predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42447720-6703-4e6a-8d6f-1d50033bd51a",
   "metadata": {},
   "source": [
    "# Q3. How do you interpret the coefficients of a Lasso Regression model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7faeb5d9-fc62-4ca0-bd86-d98acfcf2bae",
   "metadata": {},
   "source": [
    "Interpreting Lasso Regression coefficients is similar to interpreting coefficients in ordinary linear regression. Each coefficient represents the change in the dependent variable associated with a one-unit change in the corresponding independent variable while keeping other variables constant. The key difference is that Lasso coefficients can be exactly zero, indicating that the corresponding feature has been excluded from the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e60d8d-8893-4569-9a07-b83a6878aeff",
   "metadata": {},
   "source": [
    "# Q4. What are the tuning parameters that can be adjusted in Lasso Regression, and how do they affect the model's performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4e0cd5-5c0e-4a42-bb4d-7b97eecb8e1e",
   "metadata": {},
   "source": [
    "The main tuning parameter in Lasso Regression is 位 (lambda), which controls the strength of the L1 regularization penalty. Higher values of 位 result in stronger regularization, which tends to shrink more coefficients to zero. Lower values of 位 result in weaker regularization, allowing more coefficients to remain non-zero. By adjusting 位, you can control the trade-off between feature selection and model complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a3c0e1-45b0-4dac-b2f9-24e7a41a59ef",
   "metadata": {},
   "source": [
    "# Q5. Can Lasso Regression be used for non-linear regression problems? If yes, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8038678a-ed37-416f-907d-91bd52962e7a",
   "metadata": {},
   "source": [
    "Lasso Regression is inherently a linear regression technique, so it is most suitable for linear relationships between predictors and the target variable. However, you can apply Lasso Regression to non-linear regression problems by transforming your predictors or using polynomial features to capture non-linear relationships. Alternatively, for more complex non-linear problems, you may consider other regression techniques like decision trees, random forests, or support vector regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ca3371-dcda-42b0-a799-afe4de921bfb",
   "metadata": {},
   "source": [
    "# Q6. What is the difference between Ridge Regression and Lasso Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866ecf67-771e-48a7-b2cc-5ac0f2f4c67b",
   "metadata": {},
   "source": [
    "The main difference between Ridge Regression and Lasso Regression lies in the type of regularization penalty they apply:\n",
    "\n",
    "Ridge Regression uses L2 regularization, adding the sum of squared coefficients to the loss function. It tends to shrink coefficients proportionally, reducing their magnitude but not setting them to zero.\n",
    "\n",
    "Lasso Regression uses L1 regularization, adding the sum of absolute values of coefficients to the loss function. It can set some coefficients exactly to zero, effectively performing feature selection in addition to regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52aa9a0d-e9af-44f0-b6b8-f5a204f05085",
   "metadata": {},
   "source": [
    "# Q7. Can Lasso Regression handle multicollinearity in the input features? If yes, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6348af3e-1183-49df-893c-776b149b22c9",
   "metadata": {},
   "source": [
    "Yes, Lasso Regression can handle multicollinearity (high correlation between predictors) by automatically selecting a subset of relevant features while setting others to zero. By eliminating less important predictors, it effectively addresses multicollinearity by reducing the number of correlated variables in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f903bec0-54d3-4a25-a88f-92d99003a5b0",
   "metadata": {},
   "source": [
    "# Q8. How do you choose the optimal value of the regularization parameter (lambda) in Lasso Regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac46448-f575-4a2b-ab19-08e39193ac1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
